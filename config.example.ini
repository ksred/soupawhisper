[whisper]
# Model size: tiny.en, base.en, small.en, medium.en, large-v3
model = base.en

# Device: cpu or cuda (cuda requires cuDNN)
device = cpu

# Compute type: int8 for CPU, float16 for GPU
compute_type = int8

[hotkey]
# Key to hold for recording: F12, scroll_lock, pause, etc.
key = f12

[behavior]
# If streaming is enabled by default.
default_streaming = true

# Show desktop notification
notifications = true

# Copy resulting text to clipboard
clipboard = true

# Type text into active input field
auto_type = true

# Automatically format text as sentence: capitalize first letter and add period at end
auto_sentence = true

# Delay between typing characters in seconds. Make bigger to visualize the typing process.
typing_delay = 0.01

# Save recordings to /tmp with timestamped filenames (disable automatic deletion)
save_recordings = false

[streaming]

# Silence duration in seconds required to finalize a speech chunk.
vad_silence_threshold_seconds = 1.0

# Sample rate for streaming audio and VAD (should match Whisper model, 16000 Hz recommended).
vad_sample_rate = 16000

# Size of audio chunks for SAD analysis in milliseconds. Only 10, 20, 30 are supported for now.
vad_chunk_size_ms = 20

# VAD aggressiveness threshold (0.0-3.0, lower = more sensitive).
vad_threshold = 1.0

# Audio input device: device index (e.g., 0, 8) or partial device name (e.g., "pulse", "HDA Intel").
# Leave empty to use default device. Run with --verbose to see available devices.
# audio_input_device =
